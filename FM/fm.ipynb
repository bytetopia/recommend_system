{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref\n",
    "æœ¬æ®µä»£ç æ¥è‡ªï¼šhttps://github.com/babakx/fm_tensorflow/blob/master/fm_tensorflow.ipynb\n",
    "\n",
    "å…³äºFMæ¨¡å‹çš„è¯´æ˜ï¼Œè§åšæ–‡ https://codingcat.cn/article/75\n",
    "\n",
    "## æ•°æ®é›†\n",
    "https://grouplens.org/datasets/movielens/100k/  \n",
    "æ•°æ®æ ¼å¼æ˜¯æ¯è¡Œä¸€æ¡ä¿¡æ¯ï¼Œæ¯è¡ŒåŒ…å«å››åˆ—ï¼šç”¨æˆ·idï¼Œç”µå½±idï¼Œæ‰“åˆ†ï¼Œæ—¶é—´ã€‚\n",
    "\n",
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# laod data with pandas\n",
    "cols = ['user', 'item', 'rating', 'timestamp']\n",
    "train = pd.read_csv('./data/ua.base', delimiter='\\t', names=cols)\n",
    "test = pd.read_csv('./data/ua.test', delimiter='\\t', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>887431973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>875072484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>878543541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0     1     1       5  874965758\n",
       "1     1     2       3  876893171\n",
       "2     1     3       4  878542960\n",
       "3     1     4       3  876893119\n",
       "4     1     5       3  889751712\n",
       "5     1     6       5  887431973\n",
       "6     1     7       4  875071561\n",
       "7     1     8       1  875072484\n",
       "8     1     9       5  878543541\n",
       "9     1    10       3  875693118"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢ğŸ‘‡æ–¹æ³•çš„ä½œç”¨ï¼Œæ˜¯å°†æ¯æ¡åŸå§‹æ•°æ®ï¼ˆç”µå½±idã€ç”¨æˆ·idï¼‰è½¬æ¢ä¸ºFMæ‰€éœ€è¦çš„onehotå½¢å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count \n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr    \n",
    "\n",
    "def vectorize_dic(dic, ix=None, p=None):\n",
    "    \"\"\" \n",
    "    Creates a scipy csr matrix from a list of lists (each inner list is a set of values corresponding to a feature) \n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    dic -- dictionary of feature lists. Keys are the name of features\n",
    "    ix -- index generator (default None)\n",
    "    p -- dimension of featrure space (number of columns in the sparse matrix) (default None)\n",
    "    \"\"\"\n",
    "    if (ix == None):\n",
    "        d = count(0)\n",
    "        ix = defaultdict(lambda: next(d)) \n",
    "        \n",
    "    n = len(list(dic.values())[0]) # num samples\n",
    "    g = len(list(dic.keys())) # num groups\n",
    "    nz = n * g # number of non-zeros\n",
    "\n",
    "    col_ix = np.empty(nz, dtype=int)     \n",
    "    \n",
    "    i = 0\n",
    "    for k, lis in dic.items():     \n",
    "        # append index el with k in order to prevet mapping different columns with same id to same index\n",
    "        col_ix[i::g] = [ix[str(el) + str(k)] for el in lis]\n",
    "        i += 1\n",
    "        \n",
    "    row_ix = np.repeat(np.arange(0, n), g)      \n",
    "    data = np.ones(nz)\n",
    "    \n",
    "    if (p == None):\n",
    "        p = len(ix)\n",
    "        \n",
    "    ixx = np.where(col_ix < p)\n",
    "\n",
    "    return csr.csr_matrix((data[ixx],(row_ix[ixx], col_ix[ixx])), shape=(n, p)), ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºä¾¿äºç†è§£ä¸Šé¢æ–¹æ³•çš„ä½œç”¨ï¼Œç¤ºä¾‹å¦‚ä¸‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_, ix_ = vectorize_dic({'a':[1,2,2], 'b':[2,4,3]})\n",
    "data_.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.vectorize_dic.<locals>.<lambda>()>,\n",
       "            {'1a': 0, '2a': 1, '2b': 2, '3b': 4, '4b': 3})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "æ‰€ä»¥ï¼Œç»è¿‡ä¸Šé¢çš„vectorizeæ–¹æ³•ï¼Œå°†è®­ç»ƒæ•°æ®ï¼ˆä¸€å…±3æ¡ï¼‰ï¼Œè½¬æ¢æˆFMæ‰€éœ€çš„onehotå½¢å¼äº†ã€‚data_ä¸­çš„æ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªç‰¹å¾ï¼Œix_ å­˜å‚¨äº†ç‰¹å¾çš„åç§°åŠå¯¹åº”çš„åˆ—å·ï¼Œdataçš„æ¯ä¸€è¡Œæ˜¯ä¸€æ¡è®­ç»ƒæ•°æ®ã€‚\n",
    "\n",
    "| æ ·æœ¬å· | 1a | 2a | 2b | 4b | 3b |\n",
    "|  ---  | -- | -- | -- | -- | -- |\n",
    "|   0   |  1 |  0 |  1 |  0 |  0 |\n",
    "|   1   |  0 |  1 |  0 |  1 |  0 |\n",
    "|   2   |  0 |  1 |  0 |  0 |  1 |\n",
    "\n",
    "\n",
    "æ­¤å¤–éœ€è¦æ³¨æ„ä¸€ç‚¹ï¼Œvectorizeæ–¹æ³•è¿”å›çš„æ˜¯csr_matrixï¼Œæ˜¯ä¸€ç§å‹ç¼©äº†çš„ç¨€ç–çŸ©é˜µæ ¼å¼ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨todenseè½¬æ¢æˆæˆ‘ä»¬å®¹æ˜“çœ‹æ‡‚çš„çŸ©é˜µæ ¼å¼ã€‚å…³äºcsrï¼Œæ›´å¤šä¿¡æ¯å¯ä»¥çœ‹[è¿™é‡Œ](https://link.jianshu.com/?t=https%3A%2F%2Fblog.csdn.net%2Fu012871493%2Farticle%2Fdetails%2F51593451)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "okï¼Œç†è§£äº†ä¸Šé¢çš„å‡½æ•°ä¹‹åï¼Œå¯ä»¥ç”¨å®ƒå°†æœ¬æ¬¡ç”¨åˆ°çš„æ•°æ®è½¬æ¢ä¸ºFMæ‰€éœ€çš„onehotå½¢å¼äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize data and convert them to csr matrix\n",
    "X_train, ix = vectorize_dic({'users': train.user.values, 'items': train.item.values})\n",
    "X_test, ix = vectorize_dic({'users': test.user.values, 'items': test.item.values}, ix, X_train.shape[1])\n",
    "y_train = train.rating.values\n",
    "y_test= test.rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 2623)\n",
      "(9430, 2623)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()\n",
    "\n",
    "# print shape of data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹å®šä¹‰\n",
    "\n",
    "### å®šä¹‰éœ€è¦ç”¨åˆ°çš„å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n, p = X_train.shape\n",
    "# n  è®­ç»ƒæ ·æœ¬æ•°é‡\n",
    "# p  ç‰¹å¾æ•°é‡\n",
    "\n",
    "# number of latent factors\n",
    "k = 10\n",
    "\n",
    "# design matrix\n",
    "X = tf.placeholder('float', shape=[None, p])\n",
    "# target vector\n",
    "y = tf.placeholder('float', shape=[None, 1])\n",
    "\n",
    "# bias and weights\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.zeros([p]))\n",
    "\n",
    "# interaction factors, randomly initialized \n",
    "V = tf.Variable(tf.random_normal([k, p], stddev=0.01))\n",
    "\n",
    "# estimate of y, initialized to 0.\n",
    "y_hat = tf.Variable(tf.zeros([n, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®šä¹‰FMçš„å…¬å¼\n",
    "è¿™é‡Œä½¿ç”¨ç»è¿‡æ¨å¯¼ä¹‹åçš„é‚£ä¸€ç‰ˆè®¡ç®—å…¬å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\hat{y}(\\mathbf{x}) = w_0 + \\sum_{j=1}^{p}w_jx_j + \\frac{1}{2} \\sum_{f=1}^{k} ((\\sum_{j=1}^{p}v_{j,f}x_j)^2-\\sum_{j=1}^{p}v_{j,f}^2 x_j^2)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "display(Math(r'\\hat{y}(\\mathbf{x}) = w_0 + \\sum_{j=1}^{p}w_jx_j + \\frac{1}{2} \\sum_{f=1}^{k} ((\\sum_{j=1}^{p}v_{j,f}x_j)^2-\\sum_{j=1}^{p}v_{j,f}^2 x_j^2)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-48-7b11ec4227d9>:2: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Calculate output with FM equation\n",
    "linear_terms = tf.add(w0, tf.reduce_sum(tf.multiply(W, X), 1, keep_dims=True))\n",
    "pair_interactions = (tf.multiply(0.5,\n",
    "                    tf.reduce_sum(\n",
    "                        tf.subtract(\n",
    "                            tf.pow( tf.matmul(X, tf.transpose(V)), 2),\n",
    "                            tf.matmul(tf.pow(X, 2), tf.transpose(tf.pow(V, 2)))),\n",
    "                        1, keep_dims=True)))\n",
    "y_hat = tf.add(linear_terms, pair_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®šä¹‰**æŸå¤±å‡½æ•°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda_w ||W||^2 + \\lambda_v ||V||^2$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Math(r'L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda_w ||W||^2 + \\lambda_v ||V||^2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularized sum of squares loss function over W and V\n",
    "lambda_w = tf.constant(0.001, name='lambda_w')\n",
    "lambda_v = tf.constant(0.001, name='lambda_v')\n",
    "\n",
    "l2_norm = (tf.reduce_sum(\n",
    "            tf.add(\n",
    "                tf.multiply(lambda_w, tf.pow(W, 2)),\n",
    "                tf.multiply(lambda_v, tf.pow(V, 2)))))\n",
    "\n",
    "error = tf.reduce_mean(tf.square(tf.subtract(y, y_hat)))\n",
    "loss = tf.add(error, l2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿›è¡Œå‚æ•°æ›´æ–°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\Theta_{i+1} = \\Theta_{i} - \\eta \\frac{\\delta L}{\\delta \\Theta}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Math(r'\\Theta_{i+1} = \\Theta_{i} - \\eta \\frac{\\delta L}{\\delta \\Theta}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(X_, y_=None, batch_size=-1):\n",
    "    n_samples = X_.shape[0]\n",
    "\n",
    "    if batch_size == -1:\n",
    "        batch_size = n_samples\n",
    "    if batch_size < 1:\n",
    "       raise ValueError('Parameter batch_size={} is unsupported'.format(batch_size))\n",
    "\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        upper_bound = min(i + batch_size, n_samples)\n",
    "        ret_x = X_[i:upper_bound]\n",
    "        ret_y = None\n",
    "        if y_ is not None:\n",
    "            ret_y = y_[i:i + batch_size]\n",
    "            yield (ret_x, ret_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e7393def4243b3a9faa01f1f3f7857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "\n",
    "# Launch the graph\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in tqdm(range(epochs), unit='epoch'):\n",
    "    perm = np.random.permutation(X_train.shape[0])\n",
    "    # iterate over batches\n",
    "    for bX, bY in batcher(X_train[perm], y_train[perm], batch_size):\n",
    "        sess.run(optimizer, feed_dict={X: bX.reshape(-1, p), y: bY.reshape(-1, 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1134949\n"
     ]
    }
   ],
   "source": [
    "\n",
    "errors = []\n",
    "for bX, bY in batcher(X_test, y_test):\n",
    "    errors.append(sess.run(error, feed_dict={X: bX.reshape(-1, p), y: bY.reshape(-1, 1)}))\n",
    "\n",
    "RMSE = np.sqrt(np.array(errors).mean())\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
